#!/usr/bin/env python3  
# -*- coding: utf-8 -*-
"""
æ°´åŠ¡æ•°æ®è·å–è„šæœ¬ - è°ƒè¯•ç‰ˆæœ¬
è¯¦ç»†åˆ†æAPIå“åº”
"""

import requests
import re
from bs4 import BeautifulSoup
import time
import json
from urllib.parse import urljoin
from datetime import datetime, timedelta


class DebugWaterDataScraper:
    def __init__(self):
        """åˆå§‹åŒ–HTTPçˆ¬è™«"""
        self.session = requests.Session()
        
        # ç³»ç»Ÿç™»å½•ä¿¡æ¯
        self.base_url = "http://axwater.dmas.cn"
        self.login_url = f"{self.base_url}/Login.aspx"
        self.username = "13509288500"
        self.password = "288500"
        
        # çœŸå®çš„APIç«¯ç‚¹
        self.api_url = f"{self.base_url}/reports/ashx/getRptWaterYield.ashx"
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Accept-Encoding': 'gzip, deflate',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'X-Requested-With': 'XMLHttpRequest',
            'Connection': 'keep-alive',
            'Referer': f'{self.base_url}/reports/FluxRpt.aspx'
        })
        
        # ç›®æ ‡æ°´è¡¨IDï¼ˆæŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„æ­£ç¡®æ ¼å¼ï¼‰
        self.target_meters = [
            '2501200108',
            '1261181000263',    
            '1262330402331',    
            '2520005',
            '2520006',
            '1261181000300'     
        ]
        
        # ç¦ç”¨SSLéªŒè¯è­¦å‘Š
        requests.packages.urllib3.disable_warnings()
    
    def login(self):
        """æ‰§è¡Œç™»å½•"""
        print("å¼€å§‹ç™»å½•ç³»ç»Ÿ...")
        
        try:
            response = self.session.get(self.login_url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            form = soup.find('form', {'method': 'post'}) or soup.find('form')
            
            if not form:
                return False
            
            form_data = {}
            inputs = form.find_all('input')
            for input_elem in inputs:
                name = input_elem.get('name')
                value = input_elem.get('value', '')
                if name:
                    form_data[name] = value
            
            # æ‰¾åˆ°ç”¨æˆ·åå’Œå¯†ç å­—æ®µ
            for input_elem in inputs:
                name = input_elem.get('name', '')
                input_type = input_elem.get('type', 'text')
                
                if 'user' in name.lower():
                    form_data[name] = self.username
                elif input_type == 'password':
                    form_data[name] = self.password
            
            login_response = self.session.post(self.login_url, data=form_data, timeout=15, allow_redirects=True)
            
            if "Login.aspx" not in login_response.url or "ThinkWater" in login_response.text:
                print("âœ… ç™»å½•æˆåŠŸï¼")
                return True
            else:
                print("âŒ ç™»å½•å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"ç™»å½•å¤±è´¥: {e}")
            return False
    
    def setup_session(self):
        """è®¾ç½®ä¼šè¯çŠ¶æ€"""
        print("æ­£åœ¨è®¾ç½®ä¼šè¯çŠ¶æ€...")
        
        try:
            report_page_url = f"{self.base_url}/reports/FluxRpt.aspx"
            response = self.session.get(report_page_url, timeout=10)
            
            if response.status_code == 200:
                print("âœ… æˆåŠŸè®¿é—®æŠ¥è¡¨é¡µé¢")
                return True
            else:
                print(f"âŒ è®¿é—®æŠ¥è¡¨é¡µé¢å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"è®¾ç½®ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def try_different_parameter_combinations(self):
        """å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆ"""
        print("æ­£åœ¨å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆ...")
        
        # ä¸åŒçš„æ—¥æœŸæ ¼å¼
        date_formats = [
            ('2025-07-24', '2025-07-31'),
            ('2025/07/24', '2025/07/31'),
            ('20250724', '20250731'),
            ('2024-07-24', '2024-07-31'),  # å†å²æ•°æ®
            ('2024/07/24', '2024/07/31'),
        ]
        
        # ä¸åŒçš„å‚æ•°ç»„åˆ
        parameter_sets = [
            # ç»„åˆ1ï¼šåŸºç¡€å‚æ•°
            {
                'meterType': '-1',
                'statisticsType': 'flux',
                'type': 'dayRpt'
            },
            # ç»„åˆ2ï¼šç®€åŒ–å‚æ•°
            {
                'meterType': '',
                'type': 'dayRpt'
            },
            # ç»„åˆ3ï¼šä¸åŒçš„typeå€¼
            {
                'meterType': '-1',
                'statisticsType': 'flux',
                'type': 'daily'
            },
            # ç»„åˆ4ï¼šåŒ…å«åˆ†é¡µå‚æ•°
            {
                'meterType': '-1',
                'statisticsType': 'flux',
                'type': 'dayRpt',
                'page': '1',
                'rows': '100'
            },
            # ç»„åˆ5ï¼šå°è¯•å®æ—¶æ•°æ®
            {
                'meterType': '-1',
                'statisticsType': 'flux',
                'type': 'realtime'
            }
        ]
        
        formatted_node_ids = "'" + "','".join(self.target_meters) + "'"
        
        for date_start, date_end in date_formats:
            for param_set in parameter_sets:
                print(f"\nğŸ”„ æµ‹è¯•ç»„åˆ - æ—¥æœŸ: {date_start}~{date_end}, å‚æ•°: {param_set}")
                
                api_params = {
                    'nodeId': formatted_node_ids,
                    'startDate': date_start,
                    'endDate': date_end,
                    **param_set
                }
                
                if self.test_api_call(api_params):
                    return True
        
        return False
    
    def test_single_meter(self):
        """æµ‹è¯•å•ä¸ªæ°´è¡¨"""
        print("æ­£åœ¨æµ‹è¯•å•ä¸ªæ°´è¡¨...")
        
        for meter_id in self.target_meters:
            print(f"\nğŸ”„ æµ‹è¯•å•ä¸ªæ°´è¡¨: '{meter_id}'")
            
            api_params = {
                'nodeId': f"'{meter_id}'",
                'startDate': '2024-07-24',
                'endDate': '2024-07-31',
                'meterType': '-1',
                'statisticsType': 'flux',
                'type': 'dayRpt'
            }
            
            if self.test_api_call(api_params):
                return True
        
        return False
    
    def test_api_call(self, params):
        """æµ‹è¯•APIè°ƒç”¨"""
        try:
            print(f"  å‚æ•°: {params}")
            
            headers = {
                'Accept': 'application/json, text/javascript, */*; q=0.01',
                'Accept-Language': 'zh-CN,zh;q=0.9',
                'Accept-Encoding': 'gzip, deflate',
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'X-Requested-With': 'XMLHttpRequest',
                'Connection': 'keep-alive',
                'Referer': f'{self.base_url}/reports/FluxRpt.aspx',
                'Origin': self.base_url,
                'Host': 'axwater.dmas.cn'
            }
            
            response = self.session.post(self.api_url, data=params, headers=headers, timeout=15)
            
            print(f"  çŠ¶æ€ç : {response.status_code}")
            print(f"  å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
            print(f"  å“åº”å¤´: {dict(response.headers)}")
            
            content = response.text.strip()
            
            if content:
                print(f"  å“åº”å†…å®¹é¢„è§ˆ: {content[:200]}...")
                
                # å°è¯•è§£æJSON
                try:
                    data = response.json()
                    print("  âœ… JSONæ•°æ®:")
                    print(json.dumps(data, indent=2, ensure_ascii=False)[:500])
                    return True
                except:
                    pass
                
                # æ£€æŸ¥HTML
                if '<table' in content or 'error' in content.lower():
                    print(f"  ğŸ“„ HTML/é”™è¯¯å†…å®¹: {content}")
                    
                return len(content) > 10  # å¦‚æœæœ‰å®è´¨å†…å®¹å°±è®¤ä¸ºæˆåŠŸ
            else:
                print("  âŒ å“åº”ä¸ºç©º")
                return False
                
        except Exception as e:
            print(f"  âŒ APIè°ƒç”¨å¤±è´¥: {e}")
            return False
    
    def debug_session_info(self):
        """è°ƒè¯•ä¼šè¯ä¿¡æ¯"""
        print("\nğŸ” ä¼šè¯è°ƒè¯•ä¿¡æ¯:")
        print(f"Cookies: {len(self.session.cookies)} ä¸ª")
        for cookie in self.session.cookies:
            print(f"  {cookie.name}={cookie.value[:50]}...")
        
        print(f"Headers: {dict(self.session.headers)}")
    
    def run_debug(self):
        """è¿è¡Œè°ƒè¯•æµç¨‹"""
        print("\n" + "="*60)
        print("ğŸ” å¼€å§‹è°ƒè¯•ç‰ˆæ°´åŠ¡æ•°æ®è·å–æµç¨‹")
        print("="*60)
        
        try:
            # 1. ç™»å½•
            if not self.login():
                print("âŒ ç™»å½•å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
                return False
            
            # 2. è®¾ç½®ä¼šè¯çŠ¶æ€
            if not self.setup_session():
                print("âŒ è®¾ç½®ä¼šè¯çŠ¶æ€å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
                return False
            
            # 3. è°ƒè¯•ä¼šè¯ä¿¡æ¯
            self.debug_session_info()
            
            # 4. å°è¯•ä¸åŒå‚æ•°ç»„åˆ
            if self.try_different_parameter_combinations():
                print("\nğŸ‰ æ‰¾åˆ°æœ‰æ•ˆçš„å‚æ•°ç»„åˆï¼")
                return True
            
            # 5. æµ‹è¯•å•ä¸ªæ°´è¡¨
            if self.test_single_meter():
                print("\nğŸ‰ å•ä¸ªæ°´è¡¨æµ‹è¯•æˆåŠŸï¼")
                return True
            
            print("\nâŒ æ‰€æœ‰è°ƒè¯•å°è¯•éƒ½å¤±è´¥äº†")
            return False
            
        except Exception as e:
            print(f"âŒ è°ƒè¯•æµç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    scraper = DebugWaterDataScraper()
    
    try:
        if scraper.run_debug():
            print("\nâœ… è°ƒè¯•æˆåŠŸæ‰¾åˆ°è§£å†³æ–¹æ¡ˆï¼")
        else:
            print("\nâŒ è°ƒè¯•æœªæ‰¾åˆ°è§£å†³æ–¹æ¡ˆ")
            
    except KeyboardInterrupt:
        print("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")


if __name__ == "__main__":
    main()