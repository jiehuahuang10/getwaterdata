#!/usr/bin/env python3  
# -*- coding: utf-8 -*-
"""
æ°´åŠ¡æ•°æ®è·å–è„šæœ¬ - å¢å¼ºç‰ˆæœ¬
ä¼˜åŒ–åŠŸèƒ½ï¼š
- å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ
- ç¯å¢ƒå˜é‡é…ç½®
- è¯·æ±‚é‡è¯•æœºåˆ¶
- è‡ªåŠ¨é‡ç™»å½•
- æ•°æ®ä¿å­˜ä¸ºJSON/CSV
- æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—
"""

import requests
import re
import argparse
import os
import sys
import json
import csv
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from bs4 import BeautifulSoup
from urllib.parse import urljoin

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenv æ˜¯å¯é€‰çš„


class EnhancedWaterDataScraper:
    def __init__(self, username: str = None, password: str = None, base_url: str = None):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆHTTPçˆ¬è™«"""
        self.session = requests.Session()
        
        # ç³»ç»Ÿç™»å½•ä¿¡æ¯ï¼ˆä¼˜å…ˆçº§ï¼šå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼ï¼‰
        self.base_url = base_url or os.getenv('WATER_BASE_URL', "http://axwater.dmas.cn")
        self.login_url = f"{self.base_url}/Login.aspx"
        self.username = username or os.getenv('WATER_USERNAME', "13509288500")
        self.password = password or os.getenv('WATER_PASSWORD', "288500")
        
        # çœŸå®çš„APIç«¯ç‚¹
        self.api_url = f"{self.base_url}/reports/ashx/getRptWaterYield.ashx"
        
        # é…ç½®æ—¥å¿—
        self.setup_logging()
        
        # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Accept-Encoding': 'gzip, deflate',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'X-Requested-With': 'XMLHttpRequest',
            'Connection': 'keep-alive',
            'Referer': f'{self.base_url}/reports/FluxRpt.aspx'
        })
        
        # é»˜è®¤æ°´è¡¨IDåˆ—è¡¨
        self.default_meters = [
            '2501200108',
            '1261181000263',
            '1262330402331', 
            '2520005',
            '2520006',
            '1261181000300'
        ]
        
        # ä¼šè¯çŠ¶æ€
        self.viewstate = ""
        self.eventvalidation = ""
        self.is_logged_in = False
        
        # é‡è¯•é…ç½®
        self.max_retries = 3
        self.retry_delay = 2
        
        # ç¦ç”¨SSLéªŒè¯è­¦å‘Š
        requests.packages.urllib3.disable_warnings()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
        logging.basicConfig(
            level=getattr(logging, log_level),
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('water_data.log', encoding='utf-8')
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def retry_on_failure(self, func, *args, **kwargs):
        """é‡è¯•æœºåˆ¶è£…é¥°å™¨"""
        for attempt in range(self.max_retries):
            try:
                result = func(*args, **kwargs)
                if result:
                    return result
            except Exception as e:
                self.logger.warning(f"å°è¯• {attempt + 1}/{self.max_retries} å¤±è´¥: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * (attempt + 1))
                else:
                    self.logger.error(f"æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")
                    raise
        return False
    
    def login(self) -> bool:
        """æ‰§è¡Œç™»å½•"""
        self.logger.info("å¼€å§‹ç™»å½•ç³»ç»Ÿ...")
        
        try:
            # è·å–ç™»å½•é¡µé¢
            response = self.session.get(self.login_url, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            form = soup.find('form', {'method': 'post'}) or soup.find('form')
            
            if not form:
                self.logger.error("æœªæ‰¾åˆ°ç™»å½•è¡¨å•")
                return False
            
            # æå–è¡¨å•æ•°æ®
            form_data = {}
            inputs = form.find_all('input')
            for input_elem in inputs:
                name = input_elem.get('name')
                value = input_elem.get('value', '')
                if name:
                    form_data[name] = value
            
            # è®¾ç½®ç™»å½•å‡­æ®
            username_field = None
            password_field = None
            
            for input_elem in inputs:
                name = input_elem.get('name', '')
                input_type = input_elem.get('type', 'text')
                
                if 'user' in name.lower():
                    username_field = name
                elif input_type == 'password':
                    password_field = name
            
            if username_field and password_field:
                form_data[username_field] = self.username
                form_data[password_field] = self.password
                
                self.logger.info("æ­£åœ¨å‘é€ç™»å½•è¯·æ±‚...")
                login_response = self.session.post(
                    self.login_url,
                    data=form_data,
                    timeout=15,
                    allow_redirects=True
                )
                
                # æ£€æŸ¥ç™»å½•æ˜¯å¦æˆåŠŸ
                if "Login.aspx" not in login_response.url or "ThinkWater" in login_response.text:
                    self.logger.info("ç™»å½•æˆåŠŸï¼")
                    self.is_logged_in = True
                    
                    # ä¿å­˜é‡è¦çš„Cookieä¿¡æ¯
                    cookies_count = len(self.session.cookies)
                    self.logger.info(f"ä¿å­˜äº† {cookies_count} ä¸ªCookie")
                    
                    return True
                else:
                    self.logger.error("ç™»å½•å¤±è´¥")
                    return False
            else:
                self.logger.error("æœªæ‰¾åˆ°ç”¨æˆ·åæˆ–å¯†ç å­—æ®µ")
                return False
                
        except Exception as e:
            self.logger.error(f"ç™»å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def setup_session_state(self) -> bool:
        """è®¾ç½®æ­£ç¡®çš„ä¼šè¯çŠ¶æ€"""
        self.logger.info("æ­£åœ¨è®¾ç½®ä¼šè¯çŠ¶æ€...")
        
        try:
            # è®¿é—®æŠ¥è¡¨é¡µé¢å»ºç«‹ä¼šè¯çŠ¶æ€
            report_page_url = f"{self.base_url}/reports/FluxRpt.aspx"
            self.logger.info(f"è®¿é—®æŠ¥è¡¨é¡µé¢: {report_page_url}")
            
            response = self.session.get(report_page_url, timeout=10)
            if response.status_code == 200:
                self.logger.info("æˆåŠŸè®¿é—®æŠ¥è¡¨é¡µé¢")
                
                # è§£æé¡µé¢è·å–å¿…è¦çš„çŠ¶æ€ä¿¡æ¯
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # è·å–ViewStateç­‰ASP.NETçŠ¶æ€
                viewstate = soup.find('input', {'name': '__VIEWSTATE'})
                eventvalidation = soup.find('input', {'name': '__EVENTVALIDATION'})
                
                if viewstate and eventvalidation:
                    self.viewstate = viewstate.get('value', '')
                    self.eventvalidation = eventvalidation.get('value', '')
                    self.logger.info("è·å–åˆ°ASP.NETçŠ¶æ€ä¿¡æ¯")
                else:
                    self.logger.warning("æœªæ‰¾åˆ°ASP.NETçŠ¶æ€ä¿¡æ¯")
                
                return True
            else:
                self.logger.error(f"è®¿é—®æŠ¥è¡¨é¡µé¢å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"è®¾ç½®ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def get_water_data_with_params(self, meter_ids: List[str], start_date: str, end_date: str) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨æŒ‡å®šå‚æ•°è·å–æ°´è¡¨æ•°æ®"""
        self.logger.info(f"æ­£åœ¨è·å–æ°´è¡¨æ•°æ®: {len(meter_ids)}ä¸ªæ°´è¡¨ï¼Œæ—¶é—´èŒƒå›´ {start_date} åˆ° {end_date}")
        
        # æ¯æ¬¡è¯·æ±‚å‰éƒ½é‡æ–°ç™»å½•å’Œè®¾ç½®ä¼šè¯çŠ¶æ€ï¼ˆè§£å†³ä¼šè¯è¶…æ—¶é—®é¢˜ï¼‰
        self.logger.info("é‡æ–°å»ºç«‹ä¼šè¯ä»¥ç¡®ä¿æ•°æ®è·å–æˆåŠŸ...")
        if not self.login():
            self.logger.error("é‡æ–°ç™»å½•å¤±è´¥")
            return None
        
        if not self.setup_session_state():
            self.logger.error("é‡æ–°è®¾ç½®ä¼šè¯çŠ¶æ€å¤±è´¥")
            return None
        
        try:
            # æ„é€ APIè¯·æ±‚å‚æ•°
            formatted_node_ids = "'" + "','".join(meter_ids) + "'"
            api_params = {
                'nodeId': formatted_node_ids,
                'startDate': start_date,
                'endDate': end_date,
                'meterType': '-1',
                'statisticsType': 'flux',
                'type': 'dayRpt'
            }
            
            self.logger.info("APIè¯·æ±‚å‚æ•°:")
            for key, value in api_params.items():
                if key == 'nodeId':
                    self.logger.info(f"  {key}: {value[:50]}...")  # æˆªæ–­é•¿IDåˆ—è¡¨
                else:
                    self.logger.info(f"  {key}: {value}")
            
            # æ›´æ–°è¯·æ±‚å¤´ï¼Œæ·»åŠ æ›´å¤šå¿…è¦çš„å¤´ä¿¡æ¯
            headers = {
                'Accept': 'application/json, text/javascript, */*; q=0.01',
                'Accept-Language': 'zh-CN,zh;q=0.9',
                'Accept-Encoding': 'gzip, deflate',
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'X-Requested-With': 'XMLHttpRequest',
                'Connection': 'keep-alive',
                'Referer': f'{self.base_url}/reports/FluxRpt.aspx',
                'Origin': self.base_url,
                'Host': 'axwater.dmas.cn',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache'
            }
            
            # æ·»åŠ ASP.NETçŠ¶æ€å‚æ•°åˆ°è¯·æ±‚æ•°æ®ä¸­
            if hasattr(self, 'viewstate') and self.viewstate:
                api_params['__VIEWSTATE'] = self.viewstate
            if hasattr(self, 'eventvalidation') and self.eventvalidation:
                api_params['__EVENTVALIDATION'] = self.eventvalidation
            
            # å‘é€APIè¯·æ±‚
            response = self.session.post(
                self.api_url,
                data=api_params,
                headers=headers,
                timeout=15
            )
            
            self.logger.info(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                return self.parse_api_response(response)
            else:
                self.logger.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"APIè¯·æ±‚è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def parse_api_response(self, response) -> Optional[Dict[str, Any]]:
        """è§£æAPIå“åº”æ•°æ®"""
        try:
            content = response.text.strip()
            self.logger.info(f"å“åº”æ•°æ®é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå“åº”
            if not content:
                self.logger.warning("å“åº”å†…å®¹ä¸ºç©º")
                return None
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç™»å½•è¶…æ—¶
            if 'ç™»å½•è¶…æ—¶' in content or 'Login.aspx' in content:
                self.logger.warning("æ£€æµ‹åˆ°ç™»å½•è¶…æ—¶ï¼Œæ ‡è®°éœ€è¦é‡æ–°ç™»å½•")
                self.is_logged_in = False
                return None
            
            # å°è¯•è§£æJSON
            try:
                data = response.json()
                self.logger.info("æˆåŠŸè§£æJSONæ•°æ®")
                self.display_water_data_summary(data)  # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
                return {
                    'success': True,
                    'data_type': 'json',
                    'data': data,
                    'raw_content': content
                }
            except json.JSONDecodeError:
                pass
            
            # æ£€æŸ¥HTMLè¡¨æ ¼
            if '<table' in content or '<tr' in content:
                soup = BeautifulSoup(content, 'html.parser')
                tables = soup.find_all('table')
                
                if tables:
                    self.logger.info("å‘ç°HTMLè¡¨æ ¼æ•°æ®")
                    table_data = self.extract_table_data(tables)
                    self.display_table_summary(table_data)  # æ˜¾ç¤ºè¡¨æ ¼æ‘˜è¦
                    return {
                        'success': True,
                        'data_type': 'html_table',
                        'data': table_data,
                        'raw_content': content
                    }
            
            # å¦‚æœå†…å®¹åŒ…å«æ°´è¡¨ç›¸å…³å­—æ®µï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆæ•°æ®
            if any(keyword in content.lower() for keyword in 
                   ['æ°´è¡¨', 'meter', 'flux', 'æµé‡', 'ç”¨æ°´é‡', 'æŠ„è¡¨', 'æ•°æ®']):
                self.logger.info("æ£€æµ‹åˆ°æ°´è¡¨ç›¸å…³æ•°æ®")
                self.logger.info(f"æ–‡æœ¬æ•°æ®é¢„è§ˆ: {content[:200]}...")
                return {
                    'success': True,
                    'data_type': 'text',
                    'data': content,
                    'raw_content': content
                }
            
            self.logger.warning("æœªè¯†åˆ«çš„å“åº”æ ¼å¼")
            self.logger.debug(f"å“åº”å†…å®¹é¢„è§ˆ: {content[:200]}...")
            return {
                'success': False,
                'data_type': 'unknown',
                'data': None,
                'raw_content': content
            }
            
        except Exception as e:
            self.logger.error(f"è§£æAPIå“åº”å¤±è´¥: {e}")
            return None
    
    def extract_table_data(self, tables) -> List[List[str]]:
        """æå–HTMLè¡¨æ ¼æ•°æ®"""
        try:
            all_table_data = []
            
            for table_idx, table in enumerate(tables):
                rows = table.find_all('tr')
                table_data = []
                
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if cells:
                        row_data = [cell.get_text(strip=True) for cell in cells]
                        if any(row_data):  # åªä¿å­˜éç©ºè¡Œ
                            table_data.append(row_data)
                
                if table_data:
                    all_table_data.extend(table_data)
            
            return all_table_data
            
        except Exception as e:
            self.logger.error(f"æå–è¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
            return []
    
    def display_water_data_summary(self, data: Dict[str, Any]) -> None:
        """æ˜¾ç¤ºæ°´è¡¨æ•°æ®æ‘˜è¦"""
        try:
            self.logger.info("=" * 60)
            self.logger.info("ğŸ“Š è·å–åˆ°çš„æ°´è¡¨æ•°æ®æ‘˜è¦:")
            self.logger.info("=" * 60)
            
            if isinstance(data, dict) and 'rows' in data:
                total = data.get('total', 0)
                rows = data.get('rows', [])
                self.logger.info(f"æ€»è®°å½•æ•°: {total}, å®é™…è¡Œæ•°: {len(rows)}")
                
                for i, row in enumerate(rows[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                    if isinstance(row, dict):
                        meter_id = row.get('ID', 'N/A')
                        meter_name = row.get('Name', 'N/A')
                        max_value = row.get('maxvalue', 'N/A')
                        min_value = row.get('minvalue', 'N/A')
                        avg_value = row.get('avg', 'N/A')
                        
                        self.logger.info(f"æ°´è¡¨ {i+1}: {meter_name} ({meter_id})")
                        if max_value != 'N/A' and max_value is not None:
                            self.logger.info(f"  æœ€å¤§å€¼: {max_value}, æœ€å°å€¼: {min_value}, å¹³å‡å€¼: {avg_value}")
                        
                        # æ˜¾ç¤ºæ¯æ—¥æ•°æ®
                        daily_data = []
                        for key, value in row.items():
                            if key.startswith('202') and value is not None:
                                daily_data.append((key, value))
                        
                        if daily_data:
                            daily_data.sort()
                            daily_str = ", ".join([f"{date}: {val}" for date, val in daily_data[:5]])
                            if len(daily_data) > 5:
                                daily_str += f"... (å…±{len(daily_data)}å¤©)"
                            self.logger.info(f"  æ¯æ—¥æ•°æ®: {daily_str}")
                
                if len(rows) > 10:
                    self.logger.info(f"... è¿˜æœ‰ {len(rows) - 10} ä¸ªæ°´è¡¨")
            
            self.logger.info("=" * 60)
            
        except Exception as e:
            self.logger.error(f"æ˜¾ç¤ºæ•°æ®æ‘˜è¦å¤±è´¥: {e}")
    
    def display_table_summary(self, table_data: List[List[str]]) -> None:
        """æ˜¾ç¤ºè¡¨æ ¼æ•°æ®æ‘˜è¦"""
        try:
            self.logger.info("=" * 60)
            self.logger.info("ğŸ“‹ è·å–åˆ°çš„è¡¨æ ¼æ•°æ®æ‘˜è¦:")
            self.logger.info("=" * 60)
            
            if table_data:
                self.logger.info(f"è¡¨æ ¼è¡Œæ•°: {len(table_data)}")
                
                # æ˜¾ç¤ºè¡¨å¤´
                if len(table_data) > 0:
                    headers = table_data[0]
                    self.logger.info(f"è¡¨å¤´: {' | '.join(headers[:5])}{'...' if len(headers) > 5 else ''}")
                
                # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                for i, row in enumerate(table_data[1:6]):  # æ˜¾ç¤ºå‰5è¡Œæ•°æ®
                    if row:
                        row_str = " | ".join([str(cell)[:20] for cell in row[:5]])
                        if len(row) > 5:
                            row_str += "..."
                        self.logger.info(f"ç¬¬{i+1}è¡Œ: {row_str}")
                
                if len(table_data) > 6:
                    self.logger.info(f"... è¿˜æœ‰ {len(table_data) - 6} è¡Œæ•°æ®")
            
            self.logger.info("=" * 60)
            
        except Exception as e:
            self.logger.error(f"æ˜¾ç¤ºè¡¨æ ¼æ‘˜è¦å¤±è´¥: {e}")
    
    def save_data_to_json(self, data: Dict[str, Any], filename: str) -> bool:
        """ä¿å­˜æ•°æ®ä¸ºJSONæ ¼å¼"""
        try:
            output_path = Path(filename)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # æ·»åŠ å…ƒæ•°æ®
            output_data = {
                'timestamp': datetime.now().isoformat(),
                'source': 'enhanced_water_data_scraper',
                'success': data.get('success', False),
                'data_type': data.get('data_type', 'unknown'),
                'data': data.get('data'),
                'raw_content_length': len(data.get('raw_content', ''))
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°JSONæ–‡ä»¶: {filename}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def save_data_to_csv(self, data: Dict[str, Any], filename: str) -> bool:
        """ä¿å­˜æ•°æ®ä¸ºCSVæ ¼å¼"""
        try:
            output_path = Path(filename)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # æ ¹æ®æ•°æ®ç±»å‹å¤„ç†
            if data.get('data_type') == 'json' and isinstance(data.get('data'), dict):
                json_data = data['data']
                if 'rows' in json_data and isinstance(json_data['rows'], list):
                    rows = json_data['rows']
                    if rows and isinstance(rows[0], dict):
                        # JSONè¡¨æ ¼æ•°æ®
                        with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
                            writer = csv.DictWriter(f, fieldnames=rows[0].keys())
                            writer.writeheader()
                            writer.writerows(rows)
                        
                        self.logger.info(f"JSONæ•°æ®å·²ä¿å­˜åˆ°CSVæ–‡ä»¶: {filename}")
                        return True
            
            elif data.get('data_type') == 'html_table' and isinstance(data.get('data'), list):
                table_data = data['data']
                if table_data:
                    with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
                        writer = csv.writer(f)
                        writer.writerows(table_data)
                    
                    self.logger.info(f"è¡¨æ ¼æ•°æ®å·²ä¿å­˜åˆ°CSVæ–‡ä»¶: {filename}")
                    return True
            
            # å¦‚æœæ— æ³•è½¬æ¢ä¸ºCSVï¼Œä¿å­˜ä¸ºæ–‡æœ¬
            text_filename = str(output_path).replace('.csv', '.txt')
            with open(text_filename, 'w', encoding='utf-8') as f:
                f.write(f"æ•°æ®ç±»å‹: {data.get('data_type', 'unknown')}\n")
                f.write(f"è·å–æ—¶é—´: {datetime.now().isoformat()}\n")
                f.write("=" * 50 + "\n")
                f.write(str(data.get('data', '')))
            
            self.logger.info(f"æ•°æ®å·²ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶: {text_filename}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def try_multiple_date_ranges(self, meter_ids: List[str]) -> Optional[Dict[str, Any]]:
        """å°è¯•å¤šä¸ªæ—¥æœŸèŒƒå›´è·å–æ•°æ®"""
        # å®šä¹‰å¤šä¸ªå¯èƒ½æœ‰æ•°æ®çš„æ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨æœ€è¿‘7å¤©
        today = datetime.now()
        date_ranges = [
            # æœ€è¿‘7å¤©ï¼ˆä¼˜å…ˆï¼‰
            ((today - timedelta(days=7)).strftime('%Y-%m-%d'), 
             today.strftime('%Y-%m-%d')),
            # æœ€è¿‘8-14å¤©
            ((today - timedelta(days=14)).strftime('%Y-%m-%d'), 
             (today - timedelta(days=7)).strftime('%Y-%m-%d')),
            # æœ€è¿‘15-21å¤©
            ((today - timedelta(days=21)).strftime('%Y-%m-%d'), 
             (today - timedelta(days=14)).strftime('%Y-%m-%d')),
            # ä¸Šä¸ªæœˆåŒæœŸ
            ((today - timedelta(days=37)).strftime('%Y-%m-%d'), 
             (today - timedelta(days=30)).strftime('%Y-%m-%d')),
            # å·²çŸ¥æœ‰æ•°æ®çš„æ—¥æœŸèŒƒå›´
            ('2025-07-26', '2025-08-01'),
            ('2025-07-25', '2025-08-01'),
            ('2024-07-24', '2024-07-31'),
            ('2024-12-01', '2024-12-07'),
        ]
        
        for start_date, end_date in date_ranges:
            self.logger.info(f"å°è¯•æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
            
            result = self.get_water_data_with_params(meter_ids, start_date, end_date)
            if result and result.get('success'):
                self.logger.info(f"æˆåŠŸè·å–æ•°æ®ï¼Œæ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
                result['date_range'] = {'start': start_date, 'end': end_date}
                return result
            
            # çŸ­æš‚å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡é¢‘
            time.sleep(1)
        
        self.logger.warning("æ‰€æœ‰æ—¥æœŸèŒƒå›´éƒ½æœªèƒ½è·å–åˆ°æ•°æ®")
        return None
    
    def run(self, meter_ids: List[str] = None, start_date: str = None, end_date: str = None, 
            output_json: str = None, output_csv: str = None) -> bool:
        """è¿è¡Œå®Œæ•´çš„æ•°æ®è·å–æµç¨‹"""
        self.logger.info("å¼€å§‹å¢å¼ºç‰ˆæ°´åŠ¡æ•°æ®è·å–æµç¨‹")
        
        try:
            # 1. ç™»å½•
            if not self.retry_on_failure(self.login):
                self.logger.error("ç™»å½•å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
                return False
            
            # 2. è®¾ç½®ä¼šè¯çŠ¶æ€
            if not self.setup_session_state():
                self.logger.error("è®¾ç½®ä¼šè¯çŠ¶æ€å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
                return False
            
            # 3. è·å–æ•°æ®
            if meter_ids is None:
                meter_ids = self.default_meters
            
            if start_date and end_date:
                # ä½¿ç”¨æŒ‡å®šæ—¥æœŸèŒƒå›´
                result = self.get_water_data_with_params(meter_ids, start_date, end_date)
                if result:
                    result['date_range'] = {'start': start_date, 'end': end_date}
            else:
                # å°è¯•å¤šä¸ªæ—¥æœŸèŒƒå›´
                result = self.try_multiple_date_ranges(meter_ids)
            
            if not result or not result.get('success'):
                self.logger.error("æ— æ³•è·å–åˆ°æœ‰æ•ˆæ•°æ®")
                return False
            
            # 4. ä¿å­˜æ•°æ®
            success_count = 0
            
            if output_json:
                if self.save_data_to_json(result, output_json):
                    success_count += 1
            
            if output_csv:
                if self.save_data_to_csv(result, output_csv):
                    success_count += 1
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶å
            if not output_json and not output_csv:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                default_json = f"water_data_{timestamp}.json"
                default_csv = f"water_data_{timestamp}.csv"
                
                self.save_data_to_json(result, default_json)
                self.save_data_to_csv(result, default_csv)
                success_count += 2
            
            self.logger.info(f"æ•°æ®è·å–æµç¨‹å®Œæˆï¼æˆåŠŸä¿å­˜ {success_count} ä¸ªæ–‡ä»¶")
            return True
            
        except Exception as e:
            self.logger.error(f"æ•°æ®è·å–æµç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='å¢å¼ºç‰ˆæ°´åŠ¡æ•°æ®è·å–å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤å‚æ•°è·å–æ•°æ®
  python water_data_enhanced.py
  
  # æŒ‡å®šæ°´è¡¨IDå’Œæ—¥æœŸèŒƒå›´
  python water_data_enhanced.py -m 2501200108,2520005 -s 2024-07-24 -e 2024-07-31
  
  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python water_data_enhanced.py --json output.json --csv output.csv
  
  # ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ç™»å½•ä¿¡æ¯
  export WATER_USERNAME=your_username
  export WATER_PASSWORD=your_password
  python water_data_enhanced.py
        '''
    )
    
    parser.add_argument('-u', '--username', 
                       help='ç™»å½•ç”¨æˆ·å (ä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡ WATER_USERNAME è®¾ç½®)')
    parser.add_argument('-p', '--password', 
                       help='ç™»å½•å¯†ç  (ä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡ WATER_PASSWORD è®¾ç½®)')
    parser.add_argument('--base-url', 
                       help='ç³»ç»ŸåŸºç¡€URL (é»˜è®¤: http://axwater.dmas.cn)')
    
    parser.add_argument('-m', '--meters', 
                       help='æ°´è¡¨IDåˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš” (ä¾‹å¦‚: 2501200108,2520005)')
    parser.add_argument('-s', '--start-date', 
                       help='å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)')
    parser.add_argument('-e', '--end-date', 
                       help='ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)')
    
    parser.add_argument('--json', 
                       help='JSONè¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--csv', 
                       help='CSVè¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    parser.add_argument('--log-level', 
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       default='INFO',
                       help='æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.log_level:
        os.environ['LOG_LEVEL'] = args.log_level
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    scraper = EnhancedWaterDataScraper(
        username=args.username,
        password=args.password,
        base_url=args.base_url
    )
    
    # è§£ææ°´è¡¨IDåˆ—è¡¨
    meter_ids = None
    if args.meters:
        meter_ids = [mid.strip() for mid in args.meters.split(',')]
    
    try:
        # è¿è¡Œæ•°æ®è·å–æµç¨‹
        success = scraper.run(
            meter_ids=meter_ids,
            start_date=args.start_date,
            end_date=args.end_date,
            output_json=args.json,
            output_csv=args.csv
        )
        
        if success:
            print("\nâœ… å¢å¼ºç‰ˆæ•°æ®è·å–æˆåŠŸï¼")
            sys.exit(0)
        else:
            print("\nâŒ å¢å¼ºç‰ˆæ•°æ®è·å–å¤±è´¥ï¼")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
        sys.exit(130)
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
