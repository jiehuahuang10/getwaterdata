#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆå¼ºåˆ¶è·å–çœŸå®æ•°æ® - åªä¿ç•™æˆåŠŸçš„ç­–ç•¥
"""

import requests
import json
import hashlib
import time
from bs4 import BeautifulSoup
from datetime import datetime
import random

def md5_hash(text):
    """è®¡ç®—MD5å“ˆå¸Œå€¼"""
    return hashlib.md5(text.encode('utf-8')).hexdigest()

def force_get_real_data_for_web(target_date):
    """ä¸ºWebåº”ç”¨å¼ºåˆ¶è·å–æŒ‡å®šæ—¥æœŸçš„çœŸå®æ•°æ® - ä¼˜åŒ–ç‰ˆ"""
    
    print(f"ğŸ¯ è·å– {target_date} çš„çœŸå®æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    
    # ç›´æ¥ä½¿ç”¨æˆåŠŸçš„APIè°ƒç”¨
    print(f"ğŸš€ APIè°ƒç”¨è·å–çœŸå®æ•°æ®...")
    
    try:
        result = api_get_real_data(target_date)
        if result and result.get('success'):
            print(f"âœ… APIè·å–æˆåŠŸï¼")
            return result
        else:
            print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥ï¼Œå°è¯•æœ¬åœ°æ•°æ®...")
            # å¤‡ç”¨ï¼šä»æœ¬åœ°æ–‡ä»¶è·å–
            result = get_from_local_files(target_date)
            if result and result.get('success'):
                print(f"âœ… æœ¬åœ°æ•°æ®è·å–æˆåŠŸï¼")
                return result
    except Exception as e:
        print(f"âŒ è·å–å¼‚å¸¸: {e}")
    
    # æœ€åå¤‡ç”¨ï¼šåˆ›å»ºæ ‡å‡†æ•°æ®ç»“æ„
    print("ğŸ”§ åˆ›å»ºæ ‡å‡†æ•°æ®ç»“æ„...")
    return create_data_structure(target_date)

def api_get_real_data(target_date, max_retries=2):
    """APIè·å–çœŸå®æ•°æ®"""
    
    for attempt in range(max_retries):
        print(f"  ğŸ”„ APIè°ƒç”¨ {attempt + 1}/{max_retries}")
        
        session = requests.Session()
        
        # ç™»å½•
        if not login_to_system(session):
            continue
        
        # è·å–æ•°æ®
        result = fetch_api_data(session, target_date)
        if result and result.get('success'):
            return result
        
        # çŸ­æš‚å»¶è¿Ÿåé‡è¯•
        if attempt < max_retries - 1:
            time.sleep(random.uniform(1, 3))
    
    return None

def login_to_system(session):
    """ç™»å½•åˆ°æ°´åŠ¡ç³»ç»Ÿ"""
    try:
        login_url = "http://axwater.dmas.cn/login.aspx"
        login_page = session.get(login_url, timeout=20)
        
        soup = BeautifulSoup(login_page.text, 'html.parser')
        form = soup.find('form')
        
        form_data = {}
        if form:
            for input_elem in form.find_all('input'):
                name = input_elem.get('name')
                value = input_elem.get('value', '')
                if name:
                    form_data[name] = value
        
        # è®¾ç½®ç™»å½•ä¿¡æ¯
        form_data['user'] = "13509288500"
        form_data['pwd'] = md5_hash("288500")
        
        login_response = session.post(login_url, data=form_data, timeout=20)
        
        if 'window.location' in login_response.text:
            # è®¿é—®ä¸»é¡µé¢
            main_url = "http://axwater.dmas.cn/frmMain.aspx"
            session.get(main_url, timeout=20)
            return True
        
        return False
        
    except Exception as e:
        print(f"  âŒ ç™»å½•å¼‚å¸¸: {e}")
        return False

def fetch_api_data(session, target_date):
    """ä»APIè·å–æ•°æ®"""
    try:
        # è®¿é—®æŠ¥è¡¨é¡µé¢
        report_url = "http://axwater.dmas.cn/reports/FluxRpt.aspx"
        report_response = session.get(report_url, timeout=20)
        
        if report_response.status_code != 200:
            return None
        
        # æ°´è¡¨IDåˆ—è¡¨
        meter_ids = [
            '1261181000263', '1261181000300', '1262330402331', '2190066',
            '2190493', '2501200108', '2520005', '2520006'
        ]
        
        formatted_node_ids = "'" + "','".join(meter_ids) + "'"
        
        # APIè°ƒç”¨
        api_url = "http://axwater.dmas.cn/reports/ashx/getRptWaterYield.ashx"
        api_params = {
            'nodeId': formatted_node_ids,
            'startDate': target_date,
            'endDate': target_date,
            'meterType': '-1',
            'statisticsType': 'flux',
            'type': 'dayRpt'
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'X-Requested-With': 'XMLHttpRequest',
            'Referer': report_url
        }
        
        api_response = session.post(api_url, data=api_params, headers=headers, timeout=20)
        
        if api_response.status_code == 200 and len(api_response.text.strip()) > 0:
            try:
                json_data = json.loads(api_response.text)
                if 'rows' in json_data and len(json_data['rows']) > 0:
                    # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®æ•°æ®
                    has_real_data = False
                    for row in json_data['rows']:
                        if target_date in row and isinstance(row[target_date], (int, float)):
                            has_real_data = True
                            break
                    
                    if has_real_data:
                        return {
                            'success': True,
                            'data': json_data,
                            'source': 'optimized_api_call',
                            'target_date': target_date
                        }
            except json.JSONDecodeError:
                pass
        
        return None
        
    except Exception as e:
        print(f"  âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
        return None

def get_from_local_files(target_date):
    """ä»æœ¬åœ°æ•°æ®æ–‡ä»¶è·å–"""
    
    try:
        import glob
        import os
        
        # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
        data_files = (glob.glob("*COMPLETE_8_METERS*.json") + 
                     glob.glob("WEB_COMPLETE*.json") +
                     glob.glob("REAL_*.json"))
        
        for filename in sorted(data_files, key=lambda x: os.path.getmtime(x), reverse=True):
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if 'data' in data and 'rows' in data['data']:
                    for row in data['data']['rows']:
                        if isinstance(row, dict) and target_date in row:
                            value = row[target_date]
                            if isinstance(value, (int, float)) and value > 0:
                                print(f"  âœ… åœ¨ {filename} ä¸­æ‰¾åˆ°çœŸå®æ•°æ®")
                                return {
                                    'success': True,
                                    'data': data['data'],
                                    'source': f'local_file_{filename}',
                                    'target_date': target_date
                                }
            except Exception:
                continue
        
        return None
        
    except Exception as e:
        print(f"  âŒ æœ¬åœ°æ–‡ä»¶æ£€æŸ¥å¼‚å¸¸: {e}")
        return None

def create_data_structure(target_date):
    """åˆ›å»ºæ ‡å‡†æ•°æ®ç»“æ„"""
    
    # 8ä¸ªæ°´è¡¨ä¿¡æ¯
    meter_info = [
        {'id': '1261181000263', 'name': 'è”æ–°å¤§é“DN1200æµé‡è®¡'},
        {'id': '1261181000300', 'name': 'æ–°åŸå¤§é“åŒ»é™¢DN800æµé‡è®¡'},
        {'id': '1262330402331', 'name': 'å®è¥¿æ€»è¡¨DN1200'},
        {'id': '2190066', 'name': 'ä¸‰æ±Ÿæ–°æ€»è¡¨DN800ï¼ˆ2190066ï¼‰'},
        {'id': '2190493', 'name': 'æ²™åº„æ€»è¡¨'},
        {'id': '2501200108', 'name': '2501200108'},
        {'id': '2520005', 'name': 'å¦‚ä¸°å¤§é“600ç›‘æ§è¡¨'},
        {'id': '2520006', 'name': 'ä¸‰æ£µæ ‘600ç›‘æ§è¡¨'},
    ]
    
    # åˆ›å»ºæ•°æ®è¡Œ
    rows = []
    for meter in meter_info:
        rows.append({
            'ID': meter['id'],
            'Name': meter['name'],
            target_date: None  # æ˜ç¡®æ ‡è®°ä¸ºæ— çœŸå®æ•°æ®
        })
    
    return {
        'success': True,
        'data': {
            'total': len(rows),
            'rows': rows
        },
        'source': 'optimized_data_structure',
        'target_date': target_date,
        'note': f'{target_date} æ— çœŸå®æ•°æ®ï¼Œæ‰€æœ‰æ°´è¡¨å€¼ä¸ºç©º'
    }

# æµ‹è¯•å‡½æ•°
def test_optimized():
    """æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬"""
    test_dates = ["2025-08-19", "2025-07-22", "2025-07-23"]
    
    for test_date in test_dates:
        print(f"\nğŸš€ æµ‹è¯•æ—¥æœŸ: {test_date}")
        print("=" * 50)
        
        result = force_get_real_data_for_web(test_date)
        
        if result and result.get('success'):
            print(f"âœ… æˆåŠŸè·å–æ•°æ®")
            print(f"ğŸ“Š æ•°æ®æ¥æº: {result.get('source', 'unknown')}")
            
            if 'data' in result and 'rows' in result['data']:
                print(f"ğŸ“ˆ åŒ…å« {len(result['data']['rows'])} ä¸ªæ°´è¡¨")
                
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ°´è¡¨çš„æ•°æ®
                if result['data']['rows']:
                    first_row = result['data']['rows'][0]
                    value = first_row.get(test_date, 'æ— æ•°æ®')
                    name = first_row.get('Name', 'æœªçŸ¥æ°´è¡¨')
                    print(f"ğŸ’§ ç¤ºä¾‹: {name} = {value}")
        else:
            print(f"âŒ è·å–å¤±è´¥")
        
        print("=" * 50)

if __name__ == "__main__":
    test_optimized()

