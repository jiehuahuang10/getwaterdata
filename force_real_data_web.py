#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›†æˆåˆ°Webåº”ç”¨çš„å¼ºåˆ¶è·å–çœŸå®æ•°æ®åŠŸèƒ½
"""

import requests
import json
import hashlib
import time
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import random

def md5_hash(text):
    """è®¡ç®—MD5å“ˆå¸Œå€¼"""
    return hashlib.md5(text.encode('utf-8')).hexdigest()

def force_get_real_data_for_web(target_date):
    """ä¸ºWebåº”ç”¨å¼ºåˆ¶è·å–æŒ‡å®šæ—¥æœŸçš„çœŸå®æ•°æ®"""
    
    print(f"[TARGET] å¼ºåˆ¶è·å– {target_date} çš„çœŸå®æ•°æ®ï¼ˆWebé›†æˆç‰ˆï¼‰")
    
    # ç›´æ¥ä½¿ç”¨æˆåŠŸçš„APIè°ƒç”¨ç­–ç•¥
    print(f"[START] ä½¿ç”¨APIç›´æ¥è·å–çœŸå®æ•°æ®...")
    
    try:
        # å°è¯•APIè°ƒç”¨è·å–çœŸå®æ•°æ®
        result = try_direct_api_with_retry(target_date)
        if result and result.get('success'):
            print(f"[SUCCESS] æˆåŠŸè·å–çœŸå®æ•°æ®ï¼")
            return result
        else:
            print(f"[WARNING] APIè°ƒç”¨å¤±è´¥ï¼Œå°è¯•æœ¬åœ°æ•°æ®æ–‡ä»¶...")
            # å¦‚æœAPIå¤±è´¥ï¼Œå°è¯•ä»æœ¬åœ°æ–‡ä»¶è·å–
            result = get_from_existing_data_files(target_date)
            if result and result.get('success'):
                print(f"[SUCCESS] ä»æœ¬åœ°æ–‡ä»¶è·å–æˆåŠŸï¼")
                return result
    except Exception as e:
        print(f"[ERROR] è·å–æ•°æ®å¼‚å¸¸: {e}")
    
    # å¦‚æœéƒ½å¤±è´¥ï¼Œåˆ›å»ºæ­£ç¡®çš„æ•°æ®ç»“æ„
    print("[INFO] åˆ›å»ºæ ‡å‡†æ•°æ®ç»“æ„...")
    return create_real_data_structure(target_date)

def try_direct_api_with_retry(target_date, max_retries=3):
    """ç›´æ¥APIè°ƒç”¨ï¼Œå¤šæ¬¡é‡è¯•"""
    
    for attempt in range(max_retries):
        print(f"  ğŸ”„ APIé‡è¯• {attempt + 1}/{max_retries}")
        
        session = requests.Session()
        
        # ç™»å½•
        if not login_to_system(session):
            continue
        
        # å°è¯•è·å–æ•°æ®
        result = fetch_data_from_api(session, target_date)
        if result and result.get('success'):
            return result
        
        # éšæœºå»¶è¿Ÿåé‡è¯•
        time.sleep(random.uniform(2, 5))
    
    return None



def get_from_existing_data_files(target_date):
    """ä»ç°æœ‰æ•°æ®æ–‡ä»¶ä¸­è·å–"""
    
    import glob
    import os
    
    try:
        data_files = (glob.glob("*COMPLETE_8_METERS*.json") + 
                     glob.glob("WEB_COMPLETE*.json") +
                     glob.glob("REAL_*.json"))
        
        for filename in sorted(data_files, key=lambda x: os.path.getmtime(x), reverse=True):
            print(f"  [CHECK] æ£€æŸ¥æ–‡ä»¶: {filename}")
            
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if 'data' in data and 'rows' in data['data']:
                    for row in data['data']['rows']:
                        if isinstance(row, dict) and target_date in row:
                            value = row[target_date]
                            if isinstance(value, (int, float)) and value > 0:
                                print(f"  [FOUND] åœ¨ {filename} ä¸­æ‰¾åˆ° {target_date} çš„çœŸå®æ•°æ®ï¼")
                                return {
                                    'success': True,
                                    'data': data['data'],
                                    'source': f'existing_file_{filename}',
                                    'target_date': target_date
                                }
            except Exception as e:
                print(f"  [WARNING] è¯»å– {filename} å¤±è´¥: {e}")
                continue
        
        return None
        
    except Exception as e:
        print(f"[ERROR] æ£€æŸ¥ç°æœ‰æ–‡ä»¶å¼‚å¸¸: {e}")
        return None

def login_to_system(session):
    """ç™»å½•åˆ°æ°´åŠ¡ç³»ç»Ÿ"""
    try:
        login_url = "http://axwater.dmas.cn/login.aspx"
        login_page = session.get(login_url, timeout=30)
        
        soup = BeautifulSoup(login_page.text, 'html.parser')
        form = soup.find('form')
        
        form_data = {}
        if form:
            for input_elem in form.find_all('input'):
                name = input_elem.get('name')
                value = input_elem.get('value', '')
                if name:
                    form_data[name] = value
        
        username = "13509288500"
        password = "288500"
        form_data['user'] = username
        form_data['pwd'] = md5_hash(password)
        
        login_response = session.post(login_url, data=form_data, timeout=30)
        
        if 'window.location' in login_response.text:
            # æ‰‹åŠ¨è®¿é—®ä¸»é¡µé¢
            main_url = "http://axwater.dmas.cn/frmMain.aspx"
            session.get(main_url, timeout=30)
            return True
        
        return False
        
    except Exception as e:
        print(f"  [ERROR] ç™»å½•å¼‚å¸¸: {e}")
        return False

def fetch_data_from_api(session, target_date):
    """ä»APIè·å–æ•°æ®"""
    try:
        report_url = "http://axwater.dmas.cn/reports/FluxRpt.aspx"
        report_response = session.get(report_url, timeout=10)
        
        if report_response.status_code != 200:
            return None
        
        meter_ids = [
            '1261181000263', '1261181000300', '1262330402331', '2190066',
            '2190493', '2501200108', '2520005', '2520006'
        ]
        
        formatted_node_ids = "'" + "','".join(meter_ids) + "'"
        
        api_url = "http://axwater.dmas.cn/reports/ashx/getRptWaterYield.ashx"
        api_params = {
            'nodeId': formatted_node_ids,
            'startDate': target_date,
            'endDate': target_date,
            'meterType': '-1',
            'statisticsType': 'flux',
            'type': 'dayRpt'
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'X-Requested-With': 'XMLHttpRequest',
            'Referer': report_url
        }
        
        api_response = session.post(api_url, data=api_params, headers=headers, timeout=10)
        
        if api_response.status_code == 200 and len(api_response.text.strip()) > 0:
            try:
                json_data = json.loads(api_response.text)
                if 'rows' in json_data and len(json_data['rows']) > 0:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡æ—¥æœŸçš„çœŸå®æ•°æ®
                    for row in json_data['rows']:
                        if target_date in row and isinstance(row[target_date], (int, float)):
                            return {
                                'success': True,
                                'data': json_data,
                                'source': 'force_api_direct',
                                'target_date': target_date
                            }
            except json.JSONDecodeError:
                pass
        
        return None
        
    except Exception as e:
        print(f"  [ERROR] APIè°ƒç”¨å¼‚å¸¸: {e}")
        return None

def fetch_data_from_api_range(session, start_date, end_date, target_date):
    """èŒƒå›´APIè°ƒç”¨"""
    try:
        report_url = "http://axwater.dmas.cn/reports/FluxRpt.aspx"
        report_response = session.get(report_url, timeout=10)
        
        meter_ids = [
            '1261181000263', '1261181000300', '1262330402331', '2190066',
            '2190493', '2501200108', '2520005', '2520006'
        ]
        
        formatted_node_ids = "'" + "','".join(meter_ids) + "'"
        
        api_url = "http://axwater.dmas.cn/reports/ashx/getRptWaterYield.ashx"
        api_params = {
            'nodeId': formatted_node_ids,
            'startDate': start_date,
            'endDate': end_date,
            'meterType': '-1',
            'statisticsType': 'flux',
            'type': 'dayRpt'
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
        }
        
        api_response = session.post(api_url, data=api_params, headers=headers, timeout=10)
        
        if api_response.status_code == 200 and len(api_response.text.strip()) > 0:
            try:
                json_data = json.loads(api_response.text)
                if 'rows' in json_data and len(json_data['rows']) > 0:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡æ—¥æœŸ
                    for row in json_data['rows']:
                        if target_date in row and isinstance(row[target_date], (int, float)):
                            return {
                                'success': True,
                                'data': json_data,
                                'source': f'force_api_range_{start_date}_{end_date}',
                                'target_date': target_date
                            }
            except json.JSONDecodeError:
                pass
        
        return None
        
    except Exception as e:
        print(f"  [ERROR] èŒƒå›´APIè°ƒç”¨å¼‚å¸¸: {e}")
        return None

def create_real_data_structure(target_date):
    """åˆ›å»ºçœŸå®æ•°æ®ç»“æ„ï¼ˆæœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    
    print("[INFO] åˆ›å»ºçœŸå®æ•°æ®ç»“æ„...")
    
    # æ°´è¡¨ä¿¡æ¯
    meter_info = [
        {'id': '1261181000263', 'name': 'è”æ–°å¤§é“DN1200æµé‡è®¡'},
        {'id': '1261181000300', 'name': 'æ–°åŸå¤§é“åŒ»é™¢DN800æµé‡è®¡'},
        {'id': '1262330402331', 'name': 'å®è¥¿æ€»è¡¨DN1200'},
        {'id': '2190066', 'name': 'ä¸‰æ±Ÿæ–°æ€»è¡¨DN800ï¼ˆ2190066ï¼‰'},
        {'id': '2190493', 'name': 'æ²™åº„æ€»è¡¨'},
        {'id': '2501200108', 'name': '2501200108'},
        {'id': '2520005', 'name': 'å¦‚ä¸°å¤§é“600ç›‘æ§è¡¨'},
        {'id': '2520006', 'name': 'ä¸‰æ£µæ ‘600ç›‘æ§è¡¨'},
    ]
    
    # ä»æœ€æ–°çš„æˆåŠŸæ•°æ®æ–‡ä»¶ä¸­è·å–å‚è€ƒæ•°æ®
    try:
        import glob
        import os
        
        data_files = glob.glob("*COMPLETE_8_METERS*.json")
        if data_files:
            latest_file = max(data_files, key=lambda x: os.path.getmtime(x))
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                reference_data = json.load(f)
            
            if 'data' in reference_data and 'rows' in reference_data['data']:
                # ä½¿ç”¨å‚è€ƒæ•°æ®åˆ›å»ºç›®æ ‡æ—¥æœŸçš„æ•°æ®ç»“æ„
                rows = []
                for i, meter in enumerate(meter_info):
                    if i < len(reference_data['data']['rows']):
                        ref_row = reference_data['data']['rows'][i]
                        new_row = {
                            'ID': meter['id'],
                            'Name': meter['name'],
                            target_date: None  # æ˜ç¡®æ ‡è®°ä¸ºæ— çœŸå®æ•°æ®
                        }
                        # å¤åˆ¶å…¶ä»–å­—æ®µ
                        for key, value in ref_row.items():
                            if key not in ['ID', 'Name'] and not key.startswith('2025-'):
                                new_row[key] = value
                        
                        rows.append(new_row)
                
                return {
                    'success': True,
                    'data': {
                        'total': len(rows),
                        'rows': rows
                    },
                    'source': 'structured_real_data_template',
                    'target_date': target_date,
                    'note': f'åŸºäº {latest_file} åˆ›å»ºçš„çœŸå®æ•°æ®ç»“æ„ï¼Œ{target_date} çš„å€¼ä¸ºç©ºè¡¨ç¤ºæ— çœŸå®æ•°æ®'
                }
    
    except Exception as e:
        print(f"[WARNING] åˆ›å»ºæ•°æ®ç»“æ„å¼‚å¸¸: {e}")
    
    # æœ€åŸºç¡€çš„æ•°æ®ç»“æ„
    rows = []
    for meter in meter_info:
        rows.append({
            'ID': meter['id'],
            'Name': meter['name'],
            target_date: None  # æ˜ç¡®æ ‡è®°ä¸ºæ— çœŸå®æ•°æ®
        })
    
    return {
        'success': True,
        'data': {
            'total': len(rows),
            'rows': rows
        },
        'source': 'basic_real_data_structure',
        'target_date': target_date,
        'note': f'{target_date} çš„æ‰€æœ‰æ°´è¡¨æ•°æ®ä¸ºç©ºï¼Œè¡¨ç¤ºæ— æ³•è·å–çœŸå®æ•°æ®'
    }

# æµ‹è¯•å‡½æ•°
def test_force_get_real_data():
    """æµ‹è¯•å¼ºåˆ¶è·å–çœŸå®æ•°æ®"""
    target_date = "2025-07-22"
    
    print("[TEST] æµ‹è¯•å¼ºåˆ¶è·å–çœŸå®æ•°æ®")
    print(f"[TARGET] ç›®æ ‡æ—¥æœŸ: {target_date}")
    print("=" * 60)
    
    result = force_get_real_data_for_web(target_date)
    
    if result and result.get('success'):
        print(f"\n[SUCCESS] æˆåŠŸè·å– {target_date} çš„æ•°æ®ç»“æ„ï¼")
        print(f"[INFO] æ•°æ®æ¥æº: {result.get('source', 'unknown')}")
        print(f"[INFO] è¯´æ˜: {result.get('note', 'æ— ')}")
        
        if 'data' in result and 'rows' in result['data']:
            print(f"[DATA] åŒ…å« {len(result['data']['rows'])} ä¸ªæ°´è¡¨")
            
            # æ˜¾ç¤ºæ¯ä¸ªæ°´è¡¨çš„æ•°æ®
            for row in result['data']['rows']:
                name = row.get('Name', 'æœªçŸ¥æ°´è¡¨')
                value = row.get(target_date, 'æ— æ•°æ®')
                print(f"[METER] {name}: {value}")
    else:
        print(f"\n[ERROR] æ— æ³•è·å– {target_date} çš„æ•°æ®")
    
    print("=" * 60)

if __name__ == "__main__":
    test_force_get_real_data()
